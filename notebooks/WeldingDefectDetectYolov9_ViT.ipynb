{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NZTQVRRqkxYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb556121-8329-4ad0-c6fc-c90d5b9d3429"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-telegram-bot\n",
            "  Downloading python_telegram_bot-21.3-py3-none-any.whl (631 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.6/631.6 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx~=0.27 (from python-telegram-bot)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx~=0.27->python-telegram-bot)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx~=0.27->python-telegram-bot) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx~=0.27->python-telegram-bot)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx~=0.27->python-telegram-bot) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx, python-telegram-bot\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 python-telegram-bot-21.3\n",
            "Collecting python-multipart\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: python-multipart\n",
            "Successfully installed python-multipart-0.0.9\n",
            "Cloning into 'yolov9'...\n",
            "remote: Enumerating objects: 462, done.\u001b[K\n",
            "remote: Counting objects: 100% (331/331), done.\u001b[K\n",
            "remote: Compressing objects: 100% (128/128), done.\u001b[K\n",
            "remote: Total 462 (delta 226), reused 227 (delta 200), pack-reused 131\u001b[K\n",
            "Receiving objects: 100% (462/462), 2.81 MiB | 30.27 MiB/s, done.\n",
            "Resolving deltas: 100% (232/232), done.\n",
            "/content/yolov9\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.6.2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "# @title Установка библиотек\n",
        "!pip install python-telegram-bot\n",
        "!pip install python-multipart  # Для работы с файлами\n",
        "!git clone https://github.com/sherstpasha/yolov9\n",
        "%cd yolov9\n",
        "!pip install -r requirements.txt -q\n",
        "!pip install nest_asyncio\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "file_id = '18VjW3AztQILnj_6YFHMPRuawGR-48f9A'\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "output_path = '/content/model.pt'\n",
        "gdown.download(url, output_path, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "zDVU3mWDk4TS",
        "outputId": "bfd8ec74-ad4b-4193-fe29-a75e44ca5af7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=18VjW3AztQILnj_6YFHMPRuawGR-48f9A\n",
            "From (redirected): https://drive.google.com/uc?id=18VjW3AztQILnj_6YFHMPRuawGR-48f9A&confirm=t&uuid=bd0e8c8f-3e2b-4f43-aa32-4445ca5b191f\n",
            "To: /content/model.pt\n",
            "100%|██████████| 467M/467M [00:17<00:00, 27.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/model.pt'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ЗАПУСК БОТА. Перед запуском в переменную token поместите ваш api token и путь до модели yolo YOLO_PATH"
      ],
      "metadata": {
        "id": "WjB_lAH-mSnA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "YOLO_PATH = \"/content/model.pt\""
      ],
      "metadata": {
        "id": "wnhUGyEICPxX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Запуск бота\n",
        "import os\n",
        "import zipfile\n",
        "import nest_asyncio\n",
        "import io\n",
        "import shutil\n",
        "from telegram import Update, InputFile, KeyboardButton, ReplyKeyboardMarkup, ReplyKeyboardRemove\n",
        "from telegram.ext import ApplicationBuilder, CommandHandler, MessageHandler, filters, ContextTypes\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "from yolov9.detect_function import detect_image\n",
        "from telegram.error import Forbidden\n",
        "import torch\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "\n",
        "# Словарь классов и цветов\n",
        "CLASS_NAMES = {0: 'adj', 1: 'int', 2: 'geo', 3: 'pro', 4: 'non'}\n",
        "CLASS_COLORS = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow', 4: 'purple'}\n",
        "\n",
        "# Переменные для отслеживания режима и порога confidence\n",
        "USER_MODES = {}\n",
        "USER_CONFIDENCE = {}\n",
        "\n",
        "# Максимальный размер файла в байтах (1 ГБ)\n",
        "MAX_FILE_SIZE = 1 * 1024 * 1024 * 1024\n",
        "\n",
        "# Максимальные размеры изображения\n",
        "MAX_IMAGE_SIZE = 1000, 1000\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def preprocess_image(image, image_processor):\n",
        "    transforms = Compose([\n",
        "        Resize((image_processor.size['height'], image_processor.size['width'])),\n",
        "        CenterCrop(image_processor.size['height']),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "    ])\n",
        "    return transforms(image)\n",
        "\n",
        "def process_images(image_dir, conf_thres):\n",
        "    # Результаты детекции с использованием YOLO\n",
        "    results = detect_image(weights=YOLO_PATH,\n",
        "                           source=image_dir,\n",
        "                           conf_thres=conf_thres,\n",
        "                           device=\"cpu\",)\n",
        "\n",
        "    # Инициализация модели классификации\n",
        "    output_dir = \"sherstpasha/ViT_welding_defects\"\n",
        "    model = ViTForImageClassification.from_pretrained(output_dir)\n",
        "    image_processor = ViTImageProcessor.from_pretrained(output_dir)\n",
        "    print(results)\n",
        "    # Обработка результатов детекции\n",
        "    for result in results:\n",
        "        image_path = result[\"path\"]\n",
        "        bbox = result[\"bbox\"]\n",
        "        with Image.open(image_path) as img:\n",
        "            # Вырезаем область по боксу\n",
        "            cropped_img = img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
        "            # Препроцессинг изображения для классификации\n",
        "            processed_img = preprocess_image(cropped_img, image_processor)\n",
        "            processed_img = processed_img.unsqueeze(0)  # Добавляем batch dimension\n",
        "\n",
        "            # Классификация изображения\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(processed_img)\n",
        "                logits = outputs.logits\n",
        "                predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "            # Обновление класса и конфиденциальности\n",
        "            result[\"cls\"] = predicted_class_idx\n",
        "    print(results)\n",
        "    return results\n",
        "\n",
        "# Вспомогательные функции\n",
        "def load_image(image_path):\n",
        "    return Image.open(image_path)\n",
        "\n",
        "# Функция для распаковки архива\n",
        "def unzip_file(file_data):\n",
        "    image_files = {}\n",
        "    with zipfile.ZipFile(io.BytesIO(file_data), 'r') as zip_ref:\n",
        "        for file in zip_ref.namelist():\n",
        "            if file.lower().endswith(('.bmp', '.dng', '.jpeg', '.jpg', '.mpo', '.png', '.tif', '.tiff', '.webp', '.pfm')):\n",
        "                image_files[file] = zip_ref.read(file)\n",
        "    return image_files\n",
        "\n",
        "# Функция для изменения размера изображений\n",
        "def resize_image(image):\n",
        "    original_size = image.size\n",
        "    image.thumbnail(MAX_IMAGE_SIZE, Image.LANCZOS)\n",
        "    return image, original_size\n",
        "\n",
        "# Функция для рисования боксов на изображении\n",
        "def draw_boxes(image_bytes, bboxes):\n",
        "    image = Image.open(io.BytesIO(image_bytes))\n",
        "    image, original_size = resize_image(image)\n",
        "    draw = ImageDraw.Draw(image)\n",
        "    try:\n",
        "        # Увеличение размера шрифта и установка кириллического шрифта\n",
        "        font = ImageFont.truetype(\"arial.ttf\", 40)\n",
        "    except IOError:\n",
        "        font = ImageFont.load_default()\n",
        "\n",
        "    scale_x = image.size[0] / original_size[0]\n",
        "    scale_y = image.size[1] / original_size[1]\n",
        "\n",
        "    if not bboxes:\n",
        "        draw.text((10, 10), \"\", fill='red', font=font)\n",
        "    else:\n",
        "        for bbox in bboxes:\n",
        "            box = [int(coord * scale_x) if i % 2 == 0 else int(coord * scale_y) for i, coord in enumerate(bbox['bbox'])]\n",
        "            conf = bbox['conf']\n",
        "            cls = bbox['cls']\n",
        "            color = CLASS_COLORS.get(cls, 'red')\n",
        "            label = CLASS_NAMES.get(cls, 'Unknown')\n",
        "            draw.rectangle(box, outline=color, width=3)\n",
        "            # Добавляем контур к тексту\n",
        "            text = f'{label} {conf:.2f}'\n",
        "            text_size = draw.textbbox((0, 0), text, font=font)\n",
        "            text_width = text_size[2] - text_size[0]\n",
        "            text_height = text_size[3] - text_size[1]\n",
        "            x, y = box[0], box[1] - text_height\n",
        "            draw.rectangle([x, y, x + text_width, y + text_height], fill=color)\n",
        "            text_color = 'black' if color == 'yellow' else 'white'\n",
        "            draw.text((x, y), text, fill=text_color, font=font)\n",
        "\n",
        "    output = io.BytesIO()\n",
        "    image.save(output, format='JPEG')\n",
        "    output.seek(0)\n",
        "    return output\n",
        "\n",
        "# Функция для нормализации координат\n",
        "def normalize_bbox(bbox, width, height):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = (x_min + x_max) / 2.0 / width\n",
        "    y_center = (y_min + y_max) / 2.0 / height\n",
        "    box_width = (x_max - x_min) / width\n",
        "    box_height = (y_max - y_min) / height\n",
        "    return x_center, y_center, box_width, box_height\n",
        "\n",
        "# Функция для создания архива с результатами\n",
        "def create_results_archive(results, image_files, original_filename):\n",
        "    archive_buffer = io.BytesIO()\n",
        "    with zipfile.ZipFile(archive_buffer, 'w', zipfile.ZIP_DEFLATED) as archive:\n",
        "        for image_path, bboxes in results.items():\n",
        "            img_bytes = image_files[image_path]\n",
        "            with Image.open(io.BytesIO(img_bytes)) as img:\n",
        "                img = resize_image(img)[0]\n",
        "                width, height = img.size\n",
        "            txt_content = \"\"\n",
        "            for bbox in bboxes:\n",
        "                x_center, y_center, box_width, box_height = normalize_bbox(bbox['bbox'], width, height)\n",
        "                conf = bbox['conf']\n",
        "                cls = bbox['cls']\n",
        "                txt_content += f'{cls} {x_center:.6f} {y_center:.6f} {box_width:.6f} {box_height:.6f} {conf:.6f}\\n'\n",
        "            txt_filename = os.path.splitext(image_path)[0] + '.txt'\n",
        "            archive.writestr(txt_filename, txt_content)\n",
        "    archive_buffer.seek(0)\n",
        "    archive_buffer.name = f\"{os.path.splitext(original_filename)[0]}_labels.zip\"\n",
        "    return archive_buffer\n",
        "\n",
        "# Функция для создания CSV с результатами\n",
        "def create_results_csv(results, image_files):\n",
        "    csv_buffer = io.StringIO()\n",
        "    csv_buffer.write(\"filename;class_id;rel_x;rel_y;width;height\\n\")\n",
        "    for image_path, bboxes in results.items():\n",
        "        img_bytes = image_files[image_path]\n",
        "        with Image.open(io.BytesIO(img_bytes)) as img:\n",
        "            img = resize_image(img)[0]\n",
        "            width, height = img.size\n",
        "        for bbox in bboxes:\n",
        "            x_center, y_center, box_width, box_height = normalize_bbox(bbox['bbox'], width, height)\n",
        "            cls = bbox['cls']\n",
        "            csv_buffer.write(f\"{os.path.basename(image_path)};{cls};{x_center:.6f};{y_center:.6f};{box_width:.6f};{box_height:.6f}\\n\")\n",
        "    csv_buffer.seek(0)\n",
        "    return io.BytesIO(csv_buffer.getvalue().encode('utf-8'))\n",
        "\n",
        "# Функция для создания клавиатуры\n",
        "def get_keyboard():\n",
        "    keyboard = [\n",
        "        [KeyboardButton(\"Выбрать пороговое значение\")]\n",
        "    ]\n",
        "    return ReplyKeyboardMarkup(keyboard, one_time_keyboard=False, resize_keyboard=True)\n",
        "\n",
        "# Обработчик команды /start\n",
        "async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    USER_MODES[update.effective_user.id] = None\n",
        "    USER_CONFIDENCE[update.effective_user.id] = 0.1  # Значение по умолчанию\n",
        "    await update.message.reply_text('Привет! Отправьте мне фото, изображение или архив с изображениями для обработки.', reply_markup=get_keyboard())\n",
        "\n",
        "# Функция для подсчета дефектов по классам\n",
        "def count_defects(bboxes):\n",
        "    counts = {CLASS_NAMES[cls]: 0 for cls in CLASS_NAMES}\n",
        "    for bbox in bboxes:\n",
        "        cls = bbox['cls']\n",
        "        counts[CLASS_NAMES[cls]] += 1\n",
        "    total = sum(counts.values())\n",
        "    return counts, total\n",
        "\n",
        "# Обработчик полученных файлов и сообщений\n",
        "async def handle_file(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    user_id = update.message.from_user.id\n",
        "    conf_thres = USER_CONFIDENCE.get(user_id, 0.1)\n",
        "\n",
        "    try:\n",
        "        if update.message.photo:\n",
        "            await update.message.reply_text('Изображение получено, подождите немного.')\n",
        "            file = await context.bot.get_file(update.message.photo[-1].file_id)\n",
        "            photo_bytes = await file.download_as_bytearray()\n",
        "\n",
        "            # Обрабатываем фото\n",
        "            image_dir = 'temp_image'\n",
        "            os.makedirs(image_dir, exist_ok=True)\n",
        "            with open(os.path.join(image_dir, 'photo.jpg'), 'wb') as img_file:\n",
        "                img_file.write(photo_bytes)\n",
        "\n",
        "            detection_results = process_images(image_dir, conf_thres)\n",
        "            results = {'photo.jpg': detection_results}\n",
        "            counts, total = count_defects(detection_results)\n",
        "\n",
        "            # Отправляем фото с нарисованными боксами и статистику\n",
        "            img_bytes = draw_boxes(photo_bytes, detection_results)\n",
        "            if total == 0:\n",
        "                await context.bot.send_photo(chat_id=update.message.chat_id, photo=img_bytes, caption=\"Дефектов не найдено.\")\n",
        "            else:\n",
        "                caption = \"\\n\".join([f\"{cls}: {count}\" for cls, count in counts.items()]) + f\"\\nВсего: {total}\"\n",
        "                await context.bot.send_photo(chat_id=update.message.chat_id, photo=img_bytes, caption=caption)\n",
        "\n",
        "            # Удаляем временные файлы\n",
        "            shutil.rmtree(image_dir)\n",
        "\n",
        "        elif update.message.document:\n",
        "            if update.message.document.file_size > MAX_FILE_SIZE:\n",
        "                await update.message.reply_text('Файл слишком большой. Максимальный размер файла - 1 ГБ.')\n",
        "                return\n",
        "\n",
        "            if update.message.document.mime_type.startswith('image/'):\n",
        "                await update.message.reply_text('Изображение получено, подождите немного.')\n",
        "                file = await context.bot.get_file(update.message.document.file_id)\n",
        "                photo_bytes = await file.download_as_bytearray()\n",
        "\n",
        "                # Обрабатываем фото\n",
        "                image_dir = 'temp_image'\n",
        "                os.makedirs(image_dir, exist_ok=True)\n",
        "                with open(os.path.join(image_dir, 'photo.jpg'), 'wb') as img_file:\n",
        "                    img_file.write(photo_bytes)\n",
        "\n",
        "                detection_results = process_images(image_dir, conf_thres)\n",
        "                results = {'photo.jpg': detection_results}\n",
        "                counts, total = count_defects(detection_results)\n",
        "\n",
        "                # Отправляем фото с нарисованными боксами и статистику\n",
        "                img_bytes = draw_boxes(photo_bytes, detection_results)\n",
        "                if total == 0:\n",
        "                    await context.bot.send_photo(chat_id=update.message.chat_id, photo=img_bytes, caption=\"Дефектов не найдено.\")\n",
        "                else:\n",
        "                    caption = \"\\n\".join([f\"{cls}: {count}\" for cls, count in counts.items()]) + f\"\\nВсего: {total}\"\n",
        "                    await context.bot.send_photo(chat_id=update.message.chat_id, photo=img_bytes, caption=caption)\n",
        "\n",
        "                # Удаляем временные файлы\n",
        "                shutil.rmtree(image_dir)\n",
        "\n",
        "            elif update.message.document.mime_type == 'application/zip':\n",
        "                await update.message.reply_text('Архив получен, подождите немного.')\n",
        "                file = await context.bot.get_file(update.message.document.file_id)\n",
        "                file_data = await file.download_as_bytearray()\n",
        "                original_filename = update.message.document.file_name\n",
        "\n",
        "                # Распаковываем архив\n",
        "                image_files = unzip_file(file_data)\n",
        "\n",
        "                if not image_files:\n",
        "                    await update.message.reply_text('Не найдено изображений поддерживаемых форматов в архиве.')\n",
        "                    return\n",
        "\n",
        "                # Сохраняем изображения в временную директорию для обработки\n",
        "                image_dir = 'images'\n",
        "                if os.path.exists(image_dir):\n",
        "                    shutil.rmtree(image_dir)\n",
        "                os.makedirs(image_dir)\n",
        "                for img_name, img_data in image_files.items():\n",
        "                    with open(os.path.join(image_dir, os.path.basename(img_name)), 'wb') as img_file:\n",
        "                        img_file.write(img_data)\n",
        "\n",
        "                # Обрабатываем изображения\n",
        "                detection_results = process_images(image_dir, conf_thres)\n",
        "\n",
        "                # Преобразуем результаты в нужный формат\n",
        "                results = {}\n",
        "                for result in detection_results:\n",
        "                    image_path = os.path.basename(result['path'])\n",
        "                    if image_path not in results:\n",
        "                        results[image_path] = []\n",
        "                    results[image_path].append({\n",
        "                        'bbox': result['bbox'],\n",
        "                        'conf': result['conf'],\n",
        "                        'cls': result['cls']\n",
        "                    })\n",
        "\n",
        "                # Формируем и отправляем CSV с результатами\n",
        "                results_csv = create_results_csv(results, image_files)\n",
        "                await context.bot.send_document(chat_id=update.message.chat_id, document=InputFile(results_csv, filename=\"submission.csv\"))\n",
        "\n",
        "                # Удаляем временные файлы\n",
        "                shutil.rmtree(image_dir)\n",
        "\n",
        "            else:\n",
        "                await update.message.reply_text('Пожалуйста, отправьте фото, изображение или архив с изображениями.')\n",
        "\n",
        "        else:\n",
        "            await update.message.reply_text('Пожалуйста, отправьте фото, изображение или архив с изображениями.')\n",
        "\n",
        "    except Forbidden:\n",
        "        print(f\"Bot was blocked by the user: {update.message.chat_id}\")\n",
        "    except Exception as e:\n",
        "        await update.message.reply_text(f'Произошла ошибка: {e}')\n",
        "\n",
        "# Обработчик текстовых сообщений\n",
        "async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:\n",
        "    user_id = update.message.from_user.id\n",
        "    text = update.message.text\n",
        "    if text == \"Выбрать пороговое значение\":\n",
        "        await update.message.reply_text('Введите значение порога от 1 до 99:', reply_markup=ReplyKeyboardRemove())\n",
        "        USER_MODES[user_id] = 'set_threshold'\n",
        "    elif USER_MODES.get(user_id) == 'set_threshold':\n",
        "        try:\n",
        "            value = int(text)\n",
        "            if 1 <= value <= 99:\n",
        "                USER_CONFIDENCE[user_id] = value / 100.0\n",
        "                await update.message.reply_text(f'Установлен порог confidence: {USER_CONFIDENCE[user_id]}', reply_markup=get_keyboard())\n",
        "                USER_MODES[user_id] = None\n",
        "            else:\n",
        "                await update.message.reply_text('Пожалуйста, введите значение от 1 до 99.')\n",
        "        except ValueError:\n",
        "            await update.message.reply_text('Пожалуйста, введите корректное числовое значение.')\n",
        "    else:\n",
        "        await update.message.reply_text('Пожалуйста, отправьте фото, изображение или архив с изображениями.')\n",
        "\n",
        "def main() -> None:\n",
        "    nest_asyncio.apply()  # Обходим проблему с уже запущенным event loop\n",
        "\n",
        "    # Вставьте сюда ваш токен от BotFather\n",
        "    token = '1237622548:AAGBEwjd5nhQS-XhGv4sa6Ihc06LOfZlHM4'\n",
        "\n",
        "    application = ApplicationBuilder().token(token).build()\n",
        "\n",
        "    application.add_handler(CommandHandler(\"start\", start))\n",
        "    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))\n",
        "    application.add_handler(MessageHandler(filters.Document.ALL | filters.PHOTO, handle_file))\n",
        "\n",
        "    application.run_polling()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "4xzrlL5Kl9hb",
        "outputId": "91727082-e8ef-4331-9c99-e653ff329e7b",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLO 🚀 8cda056 Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "gelan-e summary: 690 layers, 57288095 parameters, 0 gradients, 188.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [200, 616, 295, 658], 'conf': 0.013858452439308167, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [280, 667, 316, 706], 'conf': 0.027539242058992386, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [485, 635, 508, 656], 'conf': 0.04195383936166763, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [7, 657, 45, 702], 'conf': 0.27338707447052, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [934, 68, 951, 86], 'conf': 0.35361695289611816, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [111, 125, 171, 488], 'conf': 0.3917945921421051, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [449, 670, 481, 690], 'conf': 0.400166392326355, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [567, 296, 662, 336], 'conf': 0.4386722445487976, 'cls': 2}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [44, 166, 64, 185], 'conf': 0.45391377806663513, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [754, 5, 790, 164], 'conf': 0.5093706846237183, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [583, 10, 646, 41], 'conf': 0.6270243525505066, 'cls': 2}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [238, 621, 263, 655], 'conf': 0.6552433967590332, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [411, 53, 445, 86], 'conf': 0.7253684997558594, 'cls': 0}, {'path': '/content/yolov9/temp_image/photo.jpg', 'bbox': [905, 219, 930, 245], 'conf': 0.7405387759208679, 'cls': 0}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Cannot close a running event loop",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-75264dab30d4>\u001b[0m in \u001b[0;36m<cell line: 356>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-75264dab30d4>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMessageHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mALL\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPHOTO\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m     \u001b[0mapplication\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_polling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36mrun_polling\u001b[0;34m(self, poll_interval, timeout, bootstrap_retries, read_timeout, write_timeout, connect_timeout, pool_timeout, allowed_updates, drop_pending_updates, close_loop, stop_signals)\u001b[0m\n\u001b[1;32m    869\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m         return self.__run(\n\u001b[0m\u001b[1;32m    872\u001b[0m             updater_coroutine=self.updater.start_polling(\n\u001b[1;32m    873\u001b[0m                 \u001b[0mpoll_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpoll_interval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/telegram/ext/_application.py\u001b[0m in \u001b[0;36m__run\u001b[0;34m(self, updater_coroutine, stop_signals, close_loop)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mclose_loop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                     \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     def create_task(\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/unix_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_finalizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msig\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_signal_handlers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/selector_events.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot close a running event loop\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Cannot close a running event loop"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ПРЕДИКТ. Для получение предикта введите путь до папки"
      ],
      "metadata": {
        "id": "Nt30ODsTuaiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "folder_path = '/content/1'"
      ],
      "metadata": {
        "id": "NymtiCBAuguK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Запуск predict\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "def zip_folder(folder_path, output_path):\n",
        "    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
        "\n",
        "# Путь к папке с изображениями\n",
        "output_path = '/content/images.zip'\n",
        "\n",
        "# Создание архива\n",
        "zip_folder(folder_path, output_path)\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "import shutil\n",
        "import csv\n",
        "from PIL import Image\n",
        "from yolov9.detect_function import detect_image\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor\n",
        "import torch\n",
        "\n",
        "# Словарь классов и цветов\n",
        "CLASS_NAMES = {0: 'adj', 1: 'int', 2: 'geo', 3: 'pro', 4: 'non'}\n",
        "CLASS_COLORS = {0: 'red', 1: 'green', 2: 'blue', 3: 'yellow', 4: 'purple'}\n",
        "\n",
        "def preprocess_image(image, image_processor):\n",
        "    transforms = Compose([\n",
        "        Resize((image_processor.size['height'], image_processor.size['width'])),\n",
        "        CenterCrop(image_processor.size['height']),\n",
        "        ToTensor(),\n",
        "        Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "    ])\n",
        "    return transforms(image)\n",
        "\n",
        "def process_images(image_dir, conf_thres):\n",
        "    # Результаты детекции с использованием YOLO\n",
        "    results = detect_image(weights=YOLO_PATH,\n",
        "                           source=image_dir,\n",
        "                           conf_thres=conf_thres,\n",
        "                           device=\"cpu\",)\n",
        "\n",
        "    # Инициализация модели классификации\n",
        "    output_dir = \"sherstpasha/ViT_welding_defects\"\n",
        "    model = ViTForImageClassification.from_pretrained(output_dir)\n",
        "    image_processor = ViTImageProcessor.from_pretrained(output_dir)\n",
        "    print(results)\n",
        "    # Обработка результатов детекции\n",
        "    for result in results:\n",
        "        image_path = result[\"path\"]\n",
        "        bbox = result[\"bbox\"]\n",
        "        with Image.open(image_path) as img:\n",
        "            # Вырезаем область по боксу\n",
        "            cropped_img = img.crop((bbox[0], bbox[1], bbox[2], bbox[3]))\n",
        "            # Препроцессинг изображения для классификации\n",
        "            processed_img = preprocess_image(cropped_img, image_processor)\n",
        "            processed_img = processed_img.unsqueeze(0)  # Добавляем batch dimension\n",
        "\n",
        "            # Классификация изображения\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(processed_img)\n",
        "                logits = outputs.logits\n",
        "                predicted_class_idx = logits.argmax(-1).item()\n",
        "\n",
        "            # Обновление класса и конфиденциальности\n",
        "            result[\"cls\"] = predicted_class_idx\n",
        "    print(results)\n",
        "    return results\n",
        "\n",
        "# Вспомогательные функции\n",
        "def load_image(image_path):\n",
        "    return Image.open(image_path)\n",
        "\n",
        "# Функция для распаковки архива\n",
        "def unzip_file(file_path):\n",
        "    image_files = {}\n",
        "    with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "        for file in zip_ref.namelist():\n",
        "            if file.lower().endswith(('.bmp', '.dng', '.jpeg', '.jpg', '.mpo', '.png', '.tif', '.tiff', '.webp', '.pfm')):\n",
        "                image_files[file] = zip_ref.read(file)\n",
        "    return image_files\n",
        "\n",
        "# Функция для нормализации координат\n",
        "def normalize_bbox(bbox, width, height):\n",
        "    x_min, y_min, x_max, y_max = bbox\n",
        "    x_center = (x_min + x_max) / 2.0 / width\n",
        "    y_center = (y_min + y_max) / 2.0 / height\n",
        "    box_width = (x_max - x_min) / width\n",
        "    box_height = (y_max - y_min) / height\n",
        "    return x_center, y_center, box_width, box_height\n",
        "\n",
        "# Функция для создания CSV с результатами\n",
        "def create_results_csv(results, image_files):\n",
        "    csv_buffer = io.StringIO()\n",
        "    csv_buffer.write(\"filename;class_id;rel_x;rel_y;width;height;confidence\\n\")\n",
        "    for image_path, bboxes in results.items():\n",
        "        img_bytes = image_files[image_path]\n",
        "        with Image.open(io.BytesIO(img_bytes)) as img:\n",
        "            width, height = img.size\n",
        "        for bbox in bboxes:\n",
        "            x_center, y_center, box_width, box_height = normalize_bbox(bbox['bbox'], width, height)\n",
        "            cls = bbox['cls']\n",
        "            conf = bbox['conf']\n",
        "            csv_buffer.write(f\"{os.path.basename(image_path)};{cls};{x_center:.6f};{y_center:.6f};{box_width:.6f};{box_height:.6f};{conf:.6f}\\n\")\n",
        "    csv_buffer.seek(0)\n",
        "    return io.BytesIO(csv_buffer.getvalue().encode('utf-8'))\n",
        "\n",
        "# Путь к архиву с изображениями\n",
        "zip_path = '/content/images.zip'\n",
        "output_csv_path = '/content/detection_results.csv'\n",
        "\n",
        "# Распаковка архива\n",
        "image_files = unzip_file(zip_path)\n",
        "\n",
        "# Сохранение изображений во временную директорию для обработки\n",
        "image_dir = 'images'\n",
        "if os.path.exists(image_dir):\n",
        "    shutil.rmtree(image_dir)\n",
        "os.makedirs(image_dir)\n",
        "for img_name, img_data in image_files.items():\n",
        "    with open(os.path.join(image_dir, os.path.basename(img_name)), 'wb') as img_file:\n",
        "        img_file.write(img_data)\n",
        "\n",
        "# Обработка изображений\n",
        "detection_results = process_images(image_dir, conf_thres=0.1)\n",
        "\n",
        "# Преобразование результатов в нужный формат\n",
        "results = {}\n",
        "for result in detection_results:\n",
        "    image_path = os.path.basename(result['path'])\n",
        "    if image_path not in results:\n",
        "        results[image_path] = []\n",
        "    results[image_path].append({\n",
        "        'bbox': result['bbox'],\n",
        "        'conf': result['conf'],\n",
        "        'cls': result['cls']\n",
        "    })\n",
        "\n",
        "# Создание и сохранение CSV файла с результатами\n",
        "results_csv = create_results_csv(results, image_files)\n",
        "with open(output_csv_path, 'wb') as csv_file:\n",
        "    csv_file.write(results_csv.read())\n",
        "\n",
        "print(f\"Результаты обработки сохранены в {output_csv_path}\")\n",
        "\n",
        "# Удаление временных файлов\n",
        "shutil.rmtree(image_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHrZWCznrR3u",
        "outputId": "493eab1c-c0eb-4cae-bf75-c7a05676ceaa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLO 🚀 8cda056 Python-3.10.12 torch-2.3.0+cu121 CPU\n",
            "\n",
            "Fusing layers... \n",
            "gelan-e summary: 690 layers, 57288095 parameters, 0 gradients, 188.6 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [510, 206, 561, 252], 'conf': 0.14986345171928406, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [468, 150, 518, 199], 'conf': 0.1887207329273224, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1131, 265, 1162, 292], 'conf': 0.23819343745708466, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [711, 600, 750, 650], 'conf': 0.3168551027774811, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1143, 684, 1182, 750], 'conf': 0.4375549852848053, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1200, 224, 1223, 245], 'conf': 0.43843740224838257, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [102, 236, 185, 285], 'conf': 0.555185854434967, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [713, 146, 765, 186], 'conf': 0.6032208204269409, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [351, 83, 452, 142], 'conf': 0.6170739531517029, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [52, 134, 128, 202], 'conf': 0.6859706044197083, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [716, 223, 786, 305], 'conf': 0.7223070859909058, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [782, 419, 827, 474], 'conf': 0.7565463185310364, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1517, 405, 1576, 515], 'conf': 0.7966466546058655, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [675, 1006, 719, 1034], 'conf': 0.160507470369339, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1401, 101, 1428, 127], 'conf': 0.21372385323047638, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [11, 986, 67, 1053], 'conf': 0.3336796164512634, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [167, 185, 250, 730], 'conf': 0.3846478760242462, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [849, 446, 994, 501], 'conf': 0.4137093722820282, 'cls': 2}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1133, 8, 1183, 248], 'conf': 0.42175808548927307, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [873, 18, 967, 60], 'conf': 0.5972263813018799, 'cls': 2}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [620, 79, 664, 126], 'conf': 0.6108278632164001, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [67, 251, 95, 277], 'conf': 0.6123855113983154, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [357, 933, 394, 981], 'conf': 0.6145865321159363, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1358, 329, 1393, 366], 'conf': 0.6939446926116943, 'cls': 0}, {'path': '/content/yolov9/images/3 (26).jpg', 'bbox': [1736, 1475, 2082, 1694], 'conf': 0.8827058672904968, 'cls': 2}]\n",
            "[{'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [510, 206, 561, 252], 'conf': 0.14986345171928406, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [468, 150, 518, 199], 'conf': 0.1887207329273224, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1131, 265, 1162, 292], 'conf': 0.23819343745708466, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [711, 600, 750, 650], 'conf': 0.3168551027774811, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1143, 684, 1182, 750], 'conf': 0.4375549852848053, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1200, 224, 1223, 245], 'conf': 0.43843740224838257, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [102, 236, 185, 285], 'conf': 0.555185854434967, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [713, 146, 765, 186], 'conf': 0.6032208204269409, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [351, 83, 452, 142], 'conf': 0.6170739531517029, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [52, 134, 128, 202], 'conf': 0.6859706044197083, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [716, 223, 786, 305], 'conf': 0.7223070859909058, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [782, 419, 827, 474], 'conf': 0.7565463185310364, 'cls': 0}, {'path': '/content/yolov9/images/2 (12).jpg', 'bbox': [1517, 405, 1576, 515], 'conf': 0.7966466546058655, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [675, 1006, 719, 1034], 'conf': 0.160507470369339, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1401, 101, 1428, 127], 'conf': 0.21372385323047638, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [11, 986, 67, 1053], 'conf': 0.3336796164512634, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [167, 185, 250, 730], 'conf': 0.3846478760242462, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [849, 446, 994, 501], 'conf': 0.4137093722820282, 'cls': 1}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1133, 8, 1183, 248], 'conf': 0.42175808548927307, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [873, 18, 967, 60], 'conf': 0.5972263813018799, 'cls': 1}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [620, 79, 664, 126], 'conf': 0.6108278632164001, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [67, 251, 95, 277], 'conf': 0.6123855113983154, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [357, 933, 394, 981], 'conf': 0.6145865321159363, 'cls': 0}, {'path': '/content/yolov9/images/2 (2).jpg', 'bbox': [1358, 329, 1393, 366], 'conf': 0.6939446926116943, 'cls': 0}, {'path': '/content/yolov9/images/3 (26).jpg', 'bbox': [1736, 1475, 2082, 1694], 'conf': 0.8827058672904968, 'cls': 1}]\n",
            "Результаты обработки сохранены в /content/detection_results.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zuaRLXY7urCu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}